import pandas as pd
from google.cloud import storage
import io
import datetime

# Configuraci√≥n
BUCKET_NAME = "market-oracle-tesis-data-lake" 
TODAY = datetime.datetime.now().strftime("%Y-%m-%d")

def upload_synthetic_data():
    print(f"üß™ Generando datos de prueba para fecha: {TODAY}")
    
    # Simulaci√≥n de noticias financieras (T√≠tulos en ingl√©s)
    data = {
        "date": [TODAY] * 5,
        "symbol": ["AAPL", "AAPL", "TSLA", "GOOGL", "AMZN"],
        "title": [
            "Apple reports record breaking quarter earnings, stock soars", # Deber√≠a ser Positivo
            "iPhone 16 production delayed due to supply chain issues",     # Deber√≠a ser Negativo
            "Tesla autopilot causes minor accident in California",         # Deber√≠a ser Negativo
            "Google announces new AI partnership with medical centers",    # Deber√≠a ser Positivo
            "Amazon maintains steady growth in cloud sector"               # Deber√≠a ser Neutral/Positivo
        ]
    }
    
    df = pd.DataFrame(data)
    
    # Subir a GCS simulando la estructura real
    storage_client = storage.Client()
    bucket = storage_client.bucket(BUCKET_NAME)
    
    symbols = df["symbol"].unique()
    
    for symbol in symbols:
        subset = df[df["symbol"] == symbol]
        blob_name = f"data/raw/{symbol}/{TODAY}.parquet"
        
        # Convertir a Parquet en memoria
        buffer = io.BytesIO()
        subset.to_parquet(buffer, index=False)
        
        blob = bucket.blob(blob_name)
        blob.upload_from_file(buffer, rewind=True)
        print(f"‚úÖ Subido: gs://{BUCKET_NAME}/{blob_name}")

if __name__ == "__main__":
    upload_synthetic_data()